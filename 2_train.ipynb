{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "3 stages of training:\n",
    "1. Train using sinewave -> To speed up training, giving the model understanding of price-equity-reward relation.\n",
    "2. Train using jagged sinewave (optional) -> Add randomness to the sinewave training\n",
    "3. Train using sidewave -> Train using real world like volatility and random price movement\n",
    "\n",
    "This training method helps speeds up training process, because the model may not able to learn anything if it is trained using sideways or historical data on the first place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training case: DQN\n",
      "DUAL_MA\n",
      "Before processing: 7999 rows\n",
      "Processing indicator: ['SMA60', 'SMA5', 'SMA20']\n",
      "Processing derived indicator: ['V3']\n",
      "Price provider - After processing: 7940 rows\n",
      "                   datetime     close     SMA60      SMA5     SMA20        V3\n",
      "59  2024-02-20 21:14:59.999  0.994030  0.993703  0.992446  0.989578 -0.126426\n",
      "60  2024-02-20 21:19:59.999  0.993784  0.993599  0.992748  0.989812 -0.085651\n",
      "61  2024-02-20 21:24:59.999  0.993882  0.993502  0.993189  0.990005 -0.031478\n",
      "62  2024-02-20 21:29:59.999  0.992911  0.993364  0.993427  0.990137  0.006307\n",
      "63  2024-02-20 21:34:59.999  0.991865  0.993152  0.993294  0.990225  0.014347\n",
      "{'test_name': 'DQN', 'rl_algo': 'DQN', 'policy': 'MlpPolicy', 'verbose': 1, 'learning_rate': 0.001, 'gamma': 0.99999, 'batch_size': 512, 'buffer_size': 200000, 'learning_starts': 1000, 'target_update_interval': 2000, 'train_freq': 10, 'gradient_steps': 1, 'exploration_fraction': 0.1, 'exploration_initial_eps': 1.0, 'exploration_final_eps': 0.01, 'max_grad_norm': 0.5}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Finding checkpoint on: /Users/kevin/Documents/Github/rl-trading-notebook/models/DQN\n",
      "Exist? True\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Starting index: 0\n",
      "Logging to ./logs/DQN/DQN_0\n",
      "An eps end, final balance: 1043, steps: 3999, trades: 21, reward: -0.1185, price change: 100.52%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1008, steps: 3999, trades: 33, reward: -0.1999, price change: 98.31%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 986, steps: 3999, trades: 26, reward: -0.2788, price change: 99.72%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.226   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 4724     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 672739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.69e-06 |\n",
      "|    n_updates        | 67173    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 1035, steps: 3999, trades: 32, reward: -0.2427, price change: 101.19%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1003, steps: 3999, trades: 23, reward: -0.1398, price change: 100.48%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1076, steps: 3999, trades: 32, reward: -0.1715, price change: 98.88%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1038, steps: 3999, trades: 15, reward: -0.1264, price change: 98.28%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.224   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 5145     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 688735   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 5.93e-06 |\n",
      "|    n_updates        | 68773    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 980, steps: 3999, trades: 31, reward: -0.3326, price change: 99.35%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1065, steps: 3999, trades: 25, reward: -0.1041, price change: 98.18%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 978, steps: 3999, trades: 30, reward: -0.3273, price change: 98.12%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 991, steps: 3999, trades: 34, reward: -0.3712, price change: 96.85%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.224   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 5260     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 704731   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.9e-06  |\n",
      "|    n_updates        | 70372    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 1024, steps: 3999, trades: 20, reward: -0.0639, price change: 100.10%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1098, steps: 3999, trades: 28, reward: -0.0509, price change: 102.64%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 986, steps: 3999, trades: 29, reward: -0.2785, price change: 99.80%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 996, steps: 3999, trades: 26, reward: -0.2270, price change: 102.50%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.223   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 5191     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 720727   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.22e-06 |\n",
      "|    n_updates        | 71972    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 1045, steps: 3999, trades: 23, reward: -0.1275, price change: 100.96%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1000, steps: 3999, trades: 23, reward: -0.2063, price change: 98.13%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1014, steps: 3999, trades: 21, reward: -0.1179, price change: 99.18%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1010, steps: 3999, trades: 27, reward: -0.2167, price change: 99.17%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.221   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 5117     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 736723   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.55e-06 |\n",
      "|    n_updates        | 73572    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 1007, steps: 3999, trades: 25, reward: -0.1085, price change: 101.86%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1017, steps: 3999, trades: 31, reward: -0.1400, price change: 102.39%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1025, steps: 3999, trades: 32, reward: -0.2727, price change: 99.78%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1041, steps: 3999, trades: 31, reward: -0.1722, price change: 100.26%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.222   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 5069     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 752719   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 5.4e-06  |\n",
      "|    n_updates        | 75171    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 1079, steps: 3999, trades: 26, reward: -0.0463, price change: 96.94%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 974, steps: 3999, trades: 26, reward: -0.2866, price change: 98.56%\n",
      "Starting index: 0\n",
      "Model saved at 760742 timesteps\n",
      "Logging to ./logs/DQN/DQN_0\n",
      "An eps end, final balance: 1013, steps: 3999, trades: 22, reward: -0.1045, price change: 99.40%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1010, steps: 3999, trades: 30, reward: -0.2201, price change: 98.98%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.219   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 4587     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 768715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.8e-06  |\n",
      "|    n_updates        | 76771    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 1043, steps: 3999, trades: 25, reward: -0.1397, price change: 100.58%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1026, steps: 3999, trades: 28, reward: -0.1552, price change: 100.28%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1026, steps: 3999, trades: 36, reward: -0.3007, price change: 99.02%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1022, steps: 3999, trades: 35, reward: -0.2522, price change: 101.48%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.215   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 4687     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 784711   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.35e-06 |\n",
      "|    n_updates        | 78370    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 1022, steps: 3999, trades: 28, reward: -0.1926, price change: 100.55%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 929, steps: 3999, trades: 33, reward: -0.4012, price change: 98.46%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1023, steps: 3999, trades: 27, reward: -0.1926, price change: 100.06%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1009, steps: 3999, trades: 29, reward: -0.1607, price change: 103.36%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.213   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 4815     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 800707   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.79e-06 |\n",
      "|    n_updates        | 79970    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 998, steps: 3999, trades: 18, reward: -0.1461, price change: 98.91%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1044, steps: 3999, trades: 27, reward: -0.1058, price change: 96.81%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1035, steps: 3999, trades: 25, reward: -0.1264, price change: 109.64%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1004, steps: 3999, trades: 23, reward: -0.1166, price change: 97.57%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.21    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 4936     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 816703   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.04e-06 |\n",
      "|    n_updates        | 81570    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 1018, steps: 3999, trades: 34, reward: -0.2519, price change: 100.93%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 981, steps: 3999, trades: 28, reward: -0.2978, price change: 99.61%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1025, steps: 3999, trades: 26, reward: -0.1581, price change: 99.22%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 968, steps: 3999, trades: 33, reward: -0.2876, price change: 99.62%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.211   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 4974     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 832699   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.42e-06 |\n",
      "|    n_updates        | 83169    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 960, steps: 3999, trades: 26, reward: -0.2258, price change: 103.32%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1002, steps: 3999, trades: 22, reward: -0.1815, price change: 101.56%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 979, steps: 3999, trades: 21, reward: -0.2232, price change: 100.70%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1020, steps: 3999, trades: 17, reward: -0.0965, price change: 98.06%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.208   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 4966     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 848695   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.37e-06 |\n",
      "|    n_updates        | 84769    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 947, steps: 3999, trades: 32, reward: -0.3681, price change: 97.92%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 969, steps: 3999, trades: 23, reward: -0.2454, price change: 93.79%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 972, steps: 3999, trades: 27, reward: -0.3077, price change: 95.29%\n",
      "Starting index: 0\n",
      "Model saved at 860742 timesteps\n",
      "Logging to ./logs/DQN/DQN_0\n",
      "An eps end, final balance: 973, steps: 3999, trades: 26, reward: -0.2884, price change: 99.09%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.21    |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 4635     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 864691   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.23e-06 |\n",
      "|    n_updates        | 86368    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 983, steps: 3999, trades: 29, reward: -0.3344, price change: 101.05%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1003, steps: 3999, trades: 27, reward: -0.2215, price change: 98.85%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1030, steps: 3999, trades: 20, reward: -0.0850, price change: 96.24%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1006, steps: 3999, trades: 19, reward: -0.1300, price change: 96.67%\n",
      "Starting index: 0\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4e+03    |\n",
      "|    ep_rew_mean      | -0.211   |\n",
      "|    exploration_rate | 0.01     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 4210     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 880687   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.52e-06 |\n",
      "|    n_updates        | 87968    |\n",
      "----------------------------------\n",
      "An eps end, final balance: 949, steps: 3999, trades: 30, reward: -0.3811, price change: 98.71%\n",
      "Starting index: 0\n",
      "An eps end, final balance: 1012, steps: 3999, trades: 34, reward: -0.2402, price change: 95.53%\n",
      "Starting index: 0\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import os\n",
    "from src.rl.libs.config_manager import ConfigManager\n",
    "from src.train import train\n",
    "\n",
    "price_data_file = \"DOGE_5m_sideways.csv\"\n",
    "price_data_path = \"./data/generated\"\n",
    "config_file = \"DQN_default.yaml\"\n",
    "config_path = f\"./configs/{config_file}\"\n",
    "\n",
    "save_every = 100000 \n",
    "max_step = 13e6 # 13 million steps\n",
    "\n",
    "config = ConfigManager(config_path)\n",
    "train(config, save_every, max_step, price_data_file, price_data_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
